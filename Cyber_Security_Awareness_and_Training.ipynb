{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaA6Jt2YY8GIzdSmxJ8Cth",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kdavis2025/Automating-Compliance-AI-and-Machine-Learning-Approaches-to-Achieviing-CMMC-2.0-Certification/blob/main/Cyber_Security_Awareness_and_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKyPO_D1vAjM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# --- Upload Widgets ---\n",
        "historical_uploader = widgets.FileUpload(\n",
        "    accept='.csv',\n",
        "    multiple=False,\n",
        "    description='Upload historical_metrics.csv'\n",
        ")\n",
        "\n",
        "quiz_uploader = widgets.FileUpload(\n",
        "    accept='.csv',\n",
        "    multiple=False,\n",
        "    description='Upload quiz_results.csv'\n",
        ")\n",
        "\n",
        "interaction_uploader = widgets.FileUpload(\n",
        "    accept='.csv',\n",
        "    multiple=False,\n",
        "    description='Upload interaction_logs.csv'\n",
        ")\n",
        "\n",
        "display(historical_uploader, quiz_uploader, interaction_uploader)\n",
        "\n",
        "# --- Load Data Function ---\n",
        "def load_uploaded_csv(uploader):\n",
        "    if uploader.value:\n",
        "        name = list(uploader.value.keys())[0]\n",
        "        content = uploader.value[name]['content']\n",
        "        return pd.read_csv(pd.io.common.BytesIO(content))\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Wait for uploads, then process\n",
        "def on_upload_change(change):\n",
        "    # Ensure all three files are uploaded\n",
        "    if historical_uploader.value and quiz_uploader.value and interaction_uploader.value:\n",
        "        # Clear the output to display results\n",
        "        clear_output()\n",
        "\n",
        "        # Load dataframes\n",
        "        historical_df = load_uploaded_csv(historical_uploader)\n",
        "        quiz_df = load_uploaded_csv(quiz_uploader)\n",
        "        interaction_df = load_uploaded_csv(interaction_uploader)\n",
        "\n",
        "        # Display head of each for confirmation\n",
        "        print(\"Historical Metrics (first 5 rows):\")\n",
        "        display(historical_df.head())\n",
        "\n",
        "        print(\"Quiz Results (first 5 rows):\")\n",
        "        display(quiz_df.head())\n",
        "\n",
        "        print(\"Interaction Logs (first 5 rows):\")\n",
        "        display(interaction_df.head())\n",
        "\n",
        "        # --- Feature Engineering per User ---\n",
        "        # 1. From historical metrics: use average AwarenessScore and PhishingClickRate\n",
        "        user_hist = historical_df.groupby('UserID').agg({\n",
        "            'AwarenessScore': 'mean',\n",
        "            'PhishingClickRate': 'mean',\n",
        "            'ModulesCompleted': 'sum',\n",
        "            'AvgTimePerModule': 'mean'\n",
        "        }).rename(columns={\n",
        "            'AwarenessScore': 'AvgAwarenessScore',\n",
        "            'PhishingClickRate': 'AvgClickRate',\n",
        "            'ModulesCompleted': 'TotalModules',\n",
        "            'AvgTimePerModule': 'MeanModuleTime'\n",
        "        })\n",
        "\n",
        "        # 2. From quiz results: compute accuracy rate and avg response time per user\n",
        "        quiz_df['IsCorrect'] = quiz_df['IsCorrect'].astype(int)\n",
        "        user_quiz = quiz_df.groupby('UserID').agg({\n",
        "            'IsCorrect': 'mean',\n",
        "            'ResponseTimeSec': 'mean'\n",
        "        }).rename(columns={\n",
        "            'IsCorrect': 'QuizAccuracy',\n",
        "            'ResponseTimeSec': 'MeanResponseTime'\n",
        "        })\n",
        "\n",
        "        # 3. From interaction logs: count phishing simulations, hint usage, total interactions\n",
        "        interaction_df['PhishingAttempt'] = interaction_df['InteractionType'].apply(lambda x: 1 if x == 'phishing_sim' else 0)\n",
        "        interaction_df['HintUsed'] = interaction_df['HintRequested'].astype(int)\n",
        "        user_inter = interaction_df.groupby('UserID').agg({\n",
        "            'PhishingAttempt': 'sum',\n",
        "            'HintUsed': 'sum',\n",
        "            'InteractionType': 'count'\n",
        "        }).rename(columns={\n",
        "            'PhishingAttempt': 'TotalPhishingSims',\n",
        "            'HintUsed': 'TotalHints',\n",
        "            'InteractionType': 'TotalInteractions'\n",
        "        })\n",
        "\n",
        "        # Merge features\n",
        "        features = user_hist.join(user_quiz, how='left').join(user_inter, how='left').fillna(0)\n",
        "\n",
        "        # Create readiness label: AvgAwarenessScore >= 75 => Ready (1), else Not Ready (0)\n",
        "        features['ReadyLabel'] = features['AvgAwarenessScore'].apply(lambda x: 1 if x >= 75 else 0)\n",
        "\n",
        "        # Display engineered feature table\n",
        "        print(\"Engineered Features per User:\")\n",
        "        display(features)\n",
        "\n",
        "        # --- Model Training ---\n",
        "        X = features.drop(columns=['ReadyLabel'])\n",
        "        y = features['ReadyLabel']\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "        clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "\n",
        "        # --- Evaluation ---\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "        print(\"Model Performance on Test Set:\")\n",
        "        print(f\"Accuracy: {acc:.2f}\")\n",
        "        print(f\"Precision: {prec:.2f}\")\n",
        "        print(f\"Recall: {rec:.2f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "        # --- Readiness Effectiveness Analysis ---\n",
        "        # Compare average phishing click rate for Ready vs Not Ready\n",
        "        ready_group = features[features['ReadyLabel'] == 1]\n",
        "        not_ready_group = features[features['ReadyLabel'] == 0]\n",
        "\n",
        "        avg_click_ready = ready_group['AvgClickRate'].mean()\n",
        "        avg_click_not_ready = not_ready_group['AvgClickRate'].mean()\n",
        "\n",
        "        print(f\"Average Phishing Click Rate (Ready): {avg_click_ready:.3f}\")\n",
        "        print(f\"Average Phishing Click Rate (Not Ready): {avg_click_not_ready:.3f}\")\n",
        "\n",
        "        print(\"\\nInterpretation:\")\n",
        "        print(\"Users classified as 'Ready' (Avg Awareness Score â‰¥ 75) exhibit lower phishing click rates, indicating improved readiness for CMMC 2.0 compliance.\")\n",
        "\n",
        "# Attach handler to uploader widgets\n",
        "historical_uploader.observe(on_upload_change, names='value')\n",
        "quiz_uploader.observe(on_upload_change, names='value')\n",
        "interaction_uploader.observe(on_upload_change, names='value')"
      ]
    }
  ]
}